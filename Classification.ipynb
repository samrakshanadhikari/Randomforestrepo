{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4576c7-3e7f-4e11-bf86-ed0bce0540c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JIniciado o treino!\n",
      "Iniciada predição!\n",
      "\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2857    0.2000    0.2353        10\n",
      "           1     0.3846    0.5000    0.4348        10\n",
      "\n",
      "    accuracy                         0.3500        20\n",
      "   macro avg     0.3352    0.3500    0.3350        20\n",
      "weighted avg     0.3352    0.3500    0.3350        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "\n",
    "#sys.path.append(str(Path(__file__).absolute().parents[1]))\n",
    "\n",
    "os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "# Size of the dataset\n",
    "LAST_INDEX_TRAIN = -1  # Tudo = -1\n",
    "LAST_INDEX_TEST = -1  # Tudo = -1\n",
    "\n",
    "TRAIN_PERCENTAGE = 0.8\n",
    "COLUMNS_TO_REMOVE = ['Pacientes','Nome']\n",
    "TARGET_NAME = 'Diagnosticounificado'\n",
    "\n",
    "# Diagnosticounificado;T-Score L1-L4;T-Score Colo Femoral;T-Score Fêmur Total\n",
    "\n",
    "# Define the CSVs path \n",
    "FILE_PATH = 'train_database_matheus.csv'\n",
    "PLOT_PATH = '/d01/scholles/gigasistemica/matheus-giga/plots/regression/regression.png'\n",
    "\n",
    "# Define where the trained model is saved\n",
    "PATH_TRAINED_MODEL = '/d01/scholles/gigasistemica/radiomics/radiomics_rf_model.sav'\n",
    "\n",
    "def read_csv_and_split(path, separation_percentage, columns_to_remove):\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "\n",
    "    # Calculate the number of rows to be separated\n",
    "    num_rows_to_split = int(len(df) * separation_percentage)\n",
    "    \n",
    "    # Generate random indices for separation\n",
    "    split_indices = np.random.choice(df.index, size=num_rows_to_split, replace=False)\n",
    "    \n",
    "    # Create separated DataFrames\n",
    "    df_train = df.loc[split_indices]\n",
    "    df_test = df.drop(split_indices)\n",
    "    \n",
    "    # Remove the specified columns\n",
    "    df_train = df_train.drop(columns=columns_to_remove, errors='ignore')\n",
    "    df_test = df_test.drop(columns=columns_to_remove, errors='ignore')\n",
    "    \n",
    "    # Get the list of remaining columns\n",
    "    all_columns = list(df_test.columns)\n",
    "    \n",
    "    return df_train, df_test, all_columns\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    train_df, df_test, all_columns = read_csv_and_split(FILE_PATH, TRAIN_PERCENTAGE, COLUMNS_TO_REMOVE)\n",
    "    features = ['Altura da cortical (D)','Altura forame-base (D)','Altura da medular forame-superficie  da cortical (D)','Altura da cortical (E)','Altura forame-base (E)','Altura da medular forame-superficie  da cortical (E)']\n",
    "    target = [TARGET_NAME]    \n",
    "    \n",
    "    X = train_df[features].to_numpy()\n",
    "    y = train_df[target].to_numpy()\n",
    "\n",
    "    # Specifies the learning model and performs the training\n",
    "    learning_model = RandomForestClassifier(verbose=True)\n",
    "    print('Iniciado o treino!')\n",
    "    learning_model.fit(X, y.ravel())\n",
    "\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------#\n",
    "    # ------------------ Validation Code for statistics ------------------#\n",
    "    # -------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    print('Iniciada predição!')\n",
    "    x_pred = df_test[features].to_numpy()\n",
    "    y_pred = learning_model.predict(x_pred)\n",
    "    y_true = df_test[target].to_numpy()\n",
    "\n",
    "    print('\\n\\n',classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c11b9-c3ed-41c9-abc5-c410a19722a8",
   "metadata": {},
   "source": [
    "Only choosing some specific feature,probably from expert knowledge didn't produce good results. We can see accuracy is around only 30 percent.So, we have to do another way for classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
